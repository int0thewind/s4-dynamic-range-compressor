{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.model import S4ConditionalSideChainModel\n",
    "from src.parameter import ConditionalTaskParameter\n",
    "from src.utils import get_tensor_device, set_random_seed_to\n",
    "from src.dataset import SignalTrainDataset, download_signal_train_dataset_to, SwitchValue, PeakReductionValue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4 Hyper-conditioning Dynamic Range Compressor Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook contains routine to evaluate a trained S4 DRC model with hyper-conditioning.\n",
    "\n",
    "Edit and execute the code in the [Preparatory Work](#preparatory-work) section first to load the model,\n",
    "and then execude the code in the rest of the section to evaluate each individual metrics.\n",
    "Each individual evaluation task is wrapped in a function to keep variables not global."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"preparatory-work\">Preparatory Work</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the following global constant to locate the model to be evaluated.\n",
    "\n",
    "If the model is trained properly using my given script, you don't need to edit any other cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = Path('./data/SignalTrain')\n",
    "CHECKPOINT_DIR = Path('./experiment-result')\n",
    "JOB_NAME = '2023-3-30-4-20-19'\n",
    "EPOCH = '30'\n",
    "\n",
    "TESTING_DATASET_SEGMENT_LENGTH = 3.0\n",
    "TESTING_DATASET_BATCH_SIZE = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following code to load the model and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_tensor_device(apple_silicon=False)\n",
    "param = ConditionalTaskParameter.from_json(CHECKPOINT_DIR / JOB_NAME / 'config.json')\n",
    "\n",
    "set_random_seed_to(param.random_seed)\n",
    "\n",
    "download_signal_train_dataset_to(DATASET_DIR)\n",
    "testing_dataset = SignalTrainDataset(DATASET_DIR, 'test', TESTING_DATASET_SEGMENT_LENGTH)\n",
    "testing_dataloader = DataLoader(testing_dataset, TESTING_DATASET_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "model = S4ConditionalSideChainModel(\n",
    "    param.model_version,\n",
    "    param.model_control_parameter_mlp_depth,\n",
    "    param.model_control_parameter_mlp_hidden_size,\n",
    "    param.model_film_take_batch_normalization,\n",
    "    param.model_inner_audio_channel,\n",
    "    param.model_s4_hidden_size,\n",
    "    param.s4_learning_rate,\n",
    "    param.model_depth,\n",
    "    param.model_activation,\n",
    "    param.model_convert_to_decibels,\n",
    ").eval().to(device)\n",
    "model.load_state_dict(torch.load(CHECKPOINT_DIR / JOB_NAME / f'model-epoch-{EPOCH}.pth', map_location=device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Step Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_step_response():\n",
    "    in_dataset_compressing_parameter_pair = torch.tensor([\n",
    "        [0, 0],\n",
    "        [0, 5],\n",
    "        [0, 20],\n",
    "        [0, 35],\n",
    "        [0, 50],\n",
    "        [0, 65],\n",
    "        [0, 80],\n",
    "        [0, 95],\n",
    "        [0, 100],\n",
    "    ]).to(device, torch.float32)\n",
    "    in_dataset_limitating_parameter_pair = torch.tensor([\n",
    "        [1, 0],\n",
    "        [1, 5],\n",
    "        [1, 20],\n",
    "        [1, 35],\n",
    "        [1, 50],\n",
    "        [1, 65],\n",
    "        [1, 80],\n",
    "        [1, 95],\n",
    "        [1, 100],\n",
    "    ]).to(device, torch.float32)\n",
    "    out_dataset_compressing_parameter_pair = torch.tensor([\n",
    "        [0, 2],\n",
    "        [0, 18],\n",
    "        [0, 34],\n",
    "        [0, 53],\n",
    "        [0, 78],\n",
    "        [0, 97],\n",
    "    ]).to(device, torch.float32)\n",
    "    out_dataset_limitating_parameter_pair = torch.tensor([\n",
    "        [1, 2],\n",
    "        [1, 18],\n",
    "        [1, 34],\n",
    "        [1, 53],\n",
    "        [1, 78],\n",
    "        [1, 97],\n",
    "    ]).to(device, torch.float32)\n",
    "    \n",
    "    sr = testing_dataset.sample_rate\n",
    "    step_signal = torch.cat([\n",
    "        torch.zeros(int(sr * 0.1)),\n",
    "        torch.zeros(int(sr * 0.45)),\n",
    "        torch.zeros(int(sr * 0.45)) + 0.3\n",
    "    ]).to(device, torch.float32)\n",
    "    \n",
    "    in_dataset_compressing_output_signal = model(\n",
    "        step_signal.repeat(in_dataset_compressing_parameter_pair.size(0), 1),\n",
    "        in_dataset_compressing_parameter_pair,\n",
    "    )\n",
    "    in_dataset_limitating_output_signal = model(\n",
    "        step_signal.repeat(in_dataset_limitating_parameter_pair.size(0), 1),\n",
    "        in_dataset_limitating_parameter_pair,\n",
    "    )\n",
    "    out_dataset_compressing_output_signal = model(\n",
    "        step_signal.repeat(out_dataset_compressing_parameter_pair.size(0), 1),\n",
    "        out_dataset_compressing_parameter_pair,\n",
    "    )\n",
    "    out_datasetlimitatingg_output_signal = model(\n",
    "        step_signal.repeat(out_dataset_limitating_parameter_pair.size(0), 1),\n",
    "        out_dataset_limitating_parameter_pair,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Waveform Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s4-dynamic-range-compressor-WjUGfTKg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
