{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from typing import Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.backends.mps import is_available as mps_is_available\n",
    "from torch.cuda import is_available as cuda_is_available\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.11 (main, Apr  7 2023, 07:24:53) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "PyTorch version: 2.0.0\n",
      "Currently, using mps device.\n"
     ]
    }
   ],
   "source": [
    "if not sys.version_info >= (3, 10):\n",
    "    raise RuntimeError(\"This notebook requires Python 3.10 or later.\")\n",
    "print(f'Python version: {sys.version}')\n",
    "\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "device = 'cuda' if cuda_is_available() else 'mps' if mps_is_available() else 'cpu'\n",
    "print(f'Currently, using {device} device.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on Neural Network's Capability on Modeling Multiplication"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 100000\n",
    "epoch = 50000\n",
    "lr = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "    def __init__(self, input_size: int = 2, hidden_size: int = 2000, layers: Literal[1, 2] = 1):\n",
    "        super(Feedforward, self).__init__()\n",
    "\n",
    "        l = [nn.Linear(input_size, hidden_size), nn.ReLU()]\n",
    "        if layers == 2:\n",
    "            l.extend([nn.Linear(hidden_size, hidden_size), nn.ReLU()])\n",
    "        l.append(nn.Linear(hidden_size, 1))\n",
    "        # l.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*l)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Feedforward(2, 2000, 1).to(device)\n",
    "# input is (batchsize, 2)\n",
    "# output dimension is (batchsize, 1)\n",
    "criterion = torch.nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7031a9259e5490b97d915ccb105eefd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 0.11531239748001099\n",
      "Epoch 1000: train loss: 1.9180145045538666e-06\n",
      "Epoch 2000: train loss: 0.0003018889401573688\n",
      "Epoch 3000: train loss: 7.147638098103926e-05\n",
      "Epoch 4000: train loss: 0.0032092358451336622\n",
      "Epoch 5000: train loss: 6.315989139693556e-06\n",
      "Epoch 6000: train loss: 1.1285478649369907e-05\n",
      "Epoch 7000: train loss: 3.8866159002282075e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# Compute Loss\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loss: Tensor \u001b[39m=\u001b[39m criterion(y_pred\u001b[39m.\u001b[39msqueeze(), y_train)\n\u001b[0;32m---> 17\u001b[0m log_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: train loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(e, loss\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     18\u001b[0m training_bar\u001b[39m.\u001b[39mset_postfix_str(log_str)\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m e \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train()\n",
    "\n",
    "training_bar = tqdm(range(epoch))\n",
    "for e in training_bar:\n",
    "    x_train = np.random.uniform(low=-1.0, high=1.0, size=(batchsize, 2)).astype(np.float32)\n",
    "    y_train = x_train[:, 0] * x_train[:, 1]\n",
    "    x_train = torch.from_numpy(x_train).to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred: Tensor = model(x_train)\n",
    "    # Compute Loss\n",
    "    loss: Tensor = criterion(y_pred.squeeze(), y_train)\n",
    "    \n",
    "    log_str = 'Epoch {}: train loss: {}'.format(e, loss.cpu().item())\n",
    "    training_bar.set_postfix_str(log_str)\n",
    "    if e % 1000 == 0:\n",
    "        print(log_str)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss after Training 0.00016203639097511768\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    x_test = np.random.uniform(low=-1.0, high=1.0, size=(batchsize, 2)).astype(np.float32)\n",
    "    y_test = x_test[:, 0] * x_test[:, 1]\n",
    "    x_test = torch.from_numpy(x_test).to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "\n",
    "    y_pred = model(x_test)\n",
    "    after_train = criterion(y_pred.squeeze(), y_test) \n",
    "    print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In dB: -64.10428376953978\n"
     ]
    }
   ],
   "source": [
    "# What is S/N ratio in dB corresponding to MSE loss?\n",
    "actual_error = np.sqrt(after_train.item())\n",
    "print(\"In dB:\", 20 * np.log10(actual_error))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "layers hidden   time   batchsize   dB\n",
    "1        10       7s       10000  -15\n",
    "2        10      10s       10000  -42\n",
    "1       100       7s       10000  -54\n",
    "2       100      15s       10000  -52\n",
    "1       100    1m02s      100000  -55\n",
    "1      1000      35s       10000  -65\n",
    "1      1000    6m14s      100000  -64 \n",
    "2      1000    3m50s       10000  -59\n",
    "1      2000    1m06s       10000  -66\n",
    "1      2000               100000  \n",
    "2      2000   13m12s       10000  -63\n",
    "1      4000    2m04s       10000  -63\n",
    "1      4000   22m13s      100000   17 (!)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt122",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
